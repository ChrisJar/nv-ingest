{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1acc12a-712e-41e6-8e30-41f9de223543",
   "metadata": {},
   "source": [
    "# Multimodal RAG with LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c557723-257f-4746-9b84-ec77c50cf405",
   "metadata": {},
   "source": [
    "This cookbook shows how to perform RAG on the table and text extraction output of nv-ingest's pdf extraction tools using LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecfda5-137b-43da-a8d4-23dd47131be9",
   "metadata": {},
   "source": [
    "To start we'll need to make sure we have llama_index installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75fdaa-3085-4b77-9289-15276d5cd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU llama_index llama-index-embeddings-nvidia llama-index-llms-nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45412661-9516-47f9-8bea-6f857e0e173f",
   "metadata": {},
   "source": [
    "Then, we'll use nv-ingest to parse an example pdf that contains text, tables, charts, and images. We'll need to make sure to have the nv-ingest microservice up and running at localhost:7670 along with the supporting NIMs. To do this, follow the nv-ingest [quickstart guide](https://github.com/NVIDIA/nv-ingest?tab=readme-ov-file#quickstart). Once the microservice is ready we can create a job with the nv-ingest python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9337daf9-7342-427a-a95e-2d9ac9b5076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv_ingest_client.client import NvIngestClient\n",
    "from nv_ingest_client.message_clients.rest.rest_client import RestClient\n",
    "from nv_ingest_client.primitives import JobSpec\n",
    "from nv_ingest_client.primitives.tasks import ExtractTask\n",
    "\n",
    "\n",
    "from nv_ingest_client.util.file_processing.extract import extract_file_content\n",
    "import logging, time\n",
    "\n",
    "logger = logging.getLogger(\"nv_ingest_client\")\n",
    "\n",
    "file_name = \"../data/multimodal_test.pdf\"\n",
    "file_content, file_type = extract_file_content(file_name)\n",
    "\n",
    "job_spec = JobSpec(\n",
    "    document_type=file_type,\n",
    "    payload=file_content,\n",
    "    source_id=file_name,\n",
    "    source_name=file_name,\n",
    "    extended_options={\n",
    "        \"tracing_options\": {\n",
    "            \"trace\": True,\n",
    "            \"ts_send\": time.time_ns()\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa9a74c-f7e4-475d-970d-cf820cd8ea19",
   "metadata": {},
   "source": [
    "And then, we can and submit a task to extract the text and tables from the example pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f07d820-0ae6-4681-88da-3f8857ea71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_task = ExtractTask(\n",
    "    document_type=file_type,\n",
    "    extract_text=True,\n",
    "    extract_images=False,\n",
    "    extract_tables=True,\n",
    ")\n",
    "\n",
    "\n",
    "job_spec.add_task(extract_task)\n",
    "\n",
    "client = NvIngestClient(\n",
    "  message_client_hostname=\"localhost\",\n",
    "  message_client_port=7670\n",
    ")\n",
    "\n",
    "job_id = client.add_job(job_spec)\n",
    "\n",
    "client.submit_job(job_id, \"morpheus_task_queue\")\n",
    "\n",
    "result = client.fetch_job_result(job_id, timeout=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8609f938-128a-4d61-a0dd-a36fc8d2b077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_type': 'text',\n",
       " 'metadata': {'content': 'TestingDocument\\r\\nA sample document with headings and placeholder text\\r\\nIntroduction\\r\\nThis is a placeholder document that can be used for any purpose. It contains some \\r\\nheadings and some placeholder text to fill the space. The text is not important and contains \\r\\nno real value, but it is useful for testing. Below, we will have some simple tables and charts \\r\\nthat we can use to confirm Ingest is working as expected.\\r\\nTable 1\\r\\nThis table describes some animals, and some activities they might be doing in specific \\r\\nlocations.\\r\\nAnimal Activity Place\\r\\nGira@e Driving a car At the beach\\r\\nLion Putting on sunscreen At the park\\r\\nCat Jumping onto a laptop In a home o@ice\\r\\nDog Chasing a squirrel In the front yard\\r\\nChart 1\\r\\nThis chart shows some gadgets, and some very fictitious costs. Section One\\r\\nThis is the first section of the document. It has some more placeholder text to show how \\r\\nthe document looks like. The text is not meant to be meaningful or informative, but rather to \\r\\ndemonstrate the layout and formatting of the document.\\r\\n• This is the first bullet point\\r\\n• This is the second bullet point\\r\\n• This is the third bullet point\\r\\nSection Two\\r\\nThis is the second section of the document. It is more of the same as we’ve seen in the rest \\r\\nof the document. The content is meaningless, but the intent is to create a very simple \\r\\nsmoke test to ensure extraction is working as intended. This will be used in CI as time goes \\r\\non to ensure that changes we make to the library do not negatively impact our accuracy.\\r\\nTable 2\\r\\nThis table shows some popular colors that cars might come in.\\r\\nCar Color1 Color2 Color3\\r\\nCoupe White Silver Flat Gray\\r\\nSedan White Metallic Gray Matte Gray\\r\\nMinivan Gray Beige Black\\r\\nTruck Dark Gray Titanium Gray Charcoal\\r\\nConvertible Light Gray Graphite Slate Gray\\r\\nPicture\\r\\nBelow, is a high-quality picture of some shapes. Chart 2\\r\\nThis chart shows some average frequency ranges for speaker drivers.\\r\\nConclusion\\r\\nThis is the conclusion of the document. It has some more placeholder text, but the most \\r\\nimportant thing is that this is the conclusion. As we end this document, we should have \\r\\nbeen able to extract 2 tables, 2 charts, and some text including 3 bullet points.',\n",
       "  'content_metadata': {'description': 'Unstructured text from PDF document.',\n",
       "   'hierarchy': {'block': -1,\n",
       "    'line': -1,\n",
       "    'nearby_objects': {'images': {'bbox': [], 'content': []},\n",
       "     'structured': {'bbox': [], 'content': []},\n",
       "     'text': {'bbox': [], 'content': []}},\n",
       "    'page': -1,\n",
       "    'page_count': 3,\n",
       "    'span': -1},\n",
       "   'page_number': -1,\n",
       "   'subtype': '',\n",
       "   'type': 'text'},\n",
       "  'debug_metadata': None,\n",
       "  'embedding': None,\n",
       "  'error_metadata': None,\n",
       "  'image_metadata': None,\n",
       "  'info_message_metadata': None,\n",
       "  'raise_on_failure': False,\n",
       "  'source_metadata': {'access_level': 1,\n",
       "   'collection_id': '',\n",
       "   'date_created': '2024-10-08T19:16:03.465614',\n",
       "   'last_modified': '2024-10-08T19:16:03.465459',\n",
       "   'partition_id': -1,\n",
       "   'source_id': '../data/multimodal_test.pdf',\n",
       "   'source_location': '',\n",
       "   'source_name': '../data/multimodal_test.pdf',\n",
       "   'source_type': 'PDF',\n",
       "   'summary': ''},\n",
       "  'table_metadata': None,\n",
       "  'text_metadata': {'keywords': '',\n",
       "   'language': 'en',\n",
       "   'summary': '',\n",
       "   'text_location': [-1, -1, -1, -1],\n",
       "   'text_type': 'document'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a0a9c-ede6-4cef-b182-9f0b78223647",
   "metadata": {},
   "source": [
    "Now, we have the extraction results in the nv-ingest metadata format. We'll separate the content out of this and load it into LlamaIndex documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b0d5eb-f0db-4edb-a3fe-c3bfccc59227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "texts = []\n",
    "tables = []\n",
    "for element in result[0][0]:\n",
    "    if element['document_type'] == 'text':\n",
    "        texts.append(Document(text=element['metadata']['content']))\n",
    "    elif element['document_type'] == 'structured':\n",
    "        tables.append(Document(text=element['metadata']['table_metadata']['table_content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f220a41-fc55-4b6c-95e1-28b41bfdba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='2b6bac68-5e1e-4a5a-a1ff-ef78b00ca711', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='TestingDocument\\r\\nA sample document with headings and placeholder text\\r\\nIntroduction\\r\\nThis is a placeholder document that can be used for any purpose. It contains some \\r\\nheadings and some placeholder text to fill the space. The text is not important and contains \\r\\nno real value, but it is useful for testing. Below, we will have some simple tables and charts \\r\\nthat we can use to confirm Ingest is working as expected.\\r\\nTable 1\\r\\nThis table describes some animals, and some activities they might be doing in specific \\r\\nlocations.\\r\\nAnimal Activity Place\\r\\nGira@e Driving a car At the beach\\r\\nLion Putting on sunscreen At the park\\r\\nCat Jumping onto a laptop In a home o@ice\\r\\nDog Chasing a squirrel In the front yard\\r\\nChart 1\\r\\nThis chart shows some gadgets, and some very fictitious costs. Section One\\r\\nThis is the first section of the document. It has some more placeholder text to show how \\r\\nthe document looks like. The text is not meant to be meaningful or informative, but rather to \\r\\ndemonstrate the layout and formatting of the document.\\r\\n• This is the first bullet point\\r\\n• This is the second bullet point\\r\\n• This is the third bullet point\\r\\nSection Two\\r\\nThis is the second section of the document. It is more of the same as we’ve seen in the rest \\r\\nof the document. The content is meaningless, but the intent is to create a very simple \\r\\nsmoke test to ensure extraction is working as intended. This will be used in CI as time goes \\r\\non to ensure that changes we make to the library do not negatively impact our accuracy.\\r\\nTable 2\\r\\nThis table shows some popular colors that cars might come in.\\r\\nCar Color1 Color2 Color3\\r\\nCoupe White Silver Flat Gray\\r\\nSedan White Metallic Gray Matte Gray\\r\\nMinivan Gray Beige Black\\r\\nTruck Dark Gray Titanium Gray Charcoal\\r\\nConvertible Light Gray Graphite Slate Gray\\r\\nPicture\\r\\nBelow, is a high-quality picture of some shapes. Chart 2\\r\\nThis chart shows some average frequency ranges for speaker drivers.\\r\\nConclusion\\r\\nThis is the conclusion of the document. It has some more placeholder text, but the most \\r\\nimportant thing is that this is the conclusion. As we end this document, we should have \\r\\nbeen able to extract 2 tables, 2 charts, and some text including 3 bullet points.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9014cbaa-1c4a-4d5d-bf34-f41b9b0c335a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='0d2024b3-c41a-4604-9779-e83106d07d78', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='locations. Animal Activity Place Giraffe Driving a car At the beach Lion Putting on sunscreen At the park Cat Jumping onto a laptop In a home office Dog Chasing a squirrel In the front yard', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='ccfba084-b81d-4319-be0d-573bc5742d45', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This chart shows some gadgets, and some very fictitious costs. >\\\\n7938.758 ext. Print & Maroon Bookshelf Fine Art Poems Collection dla Cemicon Diamtháhn | Gadgets and their cost\\nSollywood for Coasters | 19875.075     t158.281 \\n Hammer | 19871.55 \\n Powerdrill | 12044.625 \\n Bluetooth speaker | 7598.07 \\n Minifridge | 9916.305 \\n Premium desk    Hammer - Powerdrill - Bluetooth speaker - Minifridge - Premium desk fan Dollars $- - $20.00 - $40.00 - $60.00 - $80.00 - $100.00 - $120.00 - $140.00 - $160.00 Cost    Chart 1 - Gadgets and their cost', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='49e27e70-246f-4963-8da2-22c81c7a7722', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This table shows some popular colors that cars might come in. Car Color1 Color2 Color3 Coupe White Silver Flat Gray Sedan White Metallic Gray Matte Gray Minivan Gray Beige Black Truck Dark Gray Titanium Gray Charcoal Convertible Light Gray Graphite Slate Gray', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='e456b1f7-814c-47a1-918a-e6e99766deda', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This chart shows some average frequency ranges for speaker drivers TITLE | Chart 2 \\n Frequency Range Start (Hz) | Frequency Range Start (Hz) | Frequency Range End (Hz) \\n Twitter | 12800 | 12700 \\n Midrange | 13900 | 13000 \\n Midwoofer | 9600 | 13000 \\n Subwoofer | 0.00 | 13000    Tweeter - Midrange - Midwoofer - Subwoofer Hertz (log scale) 10 - 100 - 1000 - 10000 - 100000 Frequency Range Start (Hz) - Frequency Range End (Hz)    This chart shows some average frequency ranges for speaker drivers - Frequency Ranges of Speaker Drivers', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6a9b8-83cf-4061-bf57-d50edc3978d0",
   "metadata": {},
   "source": [
    "Now, the text and table content is ready to be embedded and stored. We'll set our NVIDIA api key in order to use an embedding model from NVIDIA's API catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d693a4-e647-4c20-bea4-56fe52c74541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.nvidia import NVIDIAEmbedding\n",
    "\n",
    "# TODO: Add your NVIDIA API key here\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"<YOUR_NVIDIA_API_KEY>\"\n",
    "\n",
    "embed_model = NVIDIAEmbedding(model=\"NV-Embed-QA\")\n",
    "index = VectorStoreIndex.from_documents(texts+tables, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e23e9d-a3ad-4b80-a356-1b233633b82d",
   "metadata": {},
   "source": [
    "Next, we'll use our vectorstore to create a query engine that handles the RAG pipeline and we'll use an llm from the NVIDIA API catalog to generate the final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3eb210e-1106-4956-80a3-f950d30ac6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "llm = NVIDIA(model=\"meta/llama-3.1-405b-instruct\")\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664333b-d30a-4846-801d-e484a18efe45",
   "metadata": {},
   "source": [
    "And finally, we can ask it questions about our example PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f397a34b-4639-4f8a-81a8-5a5a416404d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dog is chasing a squirrel in the front yard.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query(\"What is the dog doing and where?\").response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22058f7-470a-4659-8fdc-5b33988c4cf5",
   "metadata": {},
   "source": [
    "## Milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a521b-aca8-4227-b73d-1c3fe8aef95b",
   "metadata": {},
   "source": [
    "Alternatively, we can use the embedding NIM and the milvus vector database packaged with NV-Ingest. This requires pymilvus and the embedding, milvus, etcd, attu, and minio microservices to be up and [running](https://github.com/NVIDIA/nv-ingest/blob/main/docs/deployment.md#launch-nv-ingest-micro-services). This has the benefit of directly sending the extraction results to the embedding microservice and then to a vector database without roundtripping between the client and the NV-Ingest microservice between each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b2b1a-367b-41bb-a153-ad86227fa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU pymilvus llama-index-vector-stores-milvus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3c662-9ea2-45f4-a600-af35802f77b9",
   "metadata": {},
   "source": [
    "First, we'll create a new job spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3891199-34ba-4117-8300-3a0d8294a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/multimodal_test.pdf\"\n",
    "file_content, file_type = extract_file_content(file_name)\n",
    "\n",
    "job_spec = JobSpec(\n",
    "    document_type=file_type,\n",
    "    payload=file_content,\n",
    "    source_id=file_name,\n",
    "    source_name=file_name,\n",
    "    extended_options={\n",
    "        \"tracing_options\": {\n",
    "            \"trace\": True,\n",
    "            \"ts_send\": time.time_ns()\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d8ce7-d800-46f9-9350-139c883e8f5a",
   "metadata": {},
   "source": [
    "Then, we'll add the extraction task again, but this time we'll also add an embed task and a vector database upload task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce6d9e1-f52f-4461-bdf1-b838c0c4c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv_ingest_client.primitives.tasks import EmbedTask\n",
    "from nv_ingest_client.primitives.tasks import VdbUploadTask\n",
    "\n",
    "extract_task = ExtractTask(\n",
    "    document_type=file_type,\n",
    "    extract_text=True,\n",
    "    extract_images=False,\n",
    "    extract_tables=True,\n",
    ")\n",
    "\n",
    "embed_task = EmbedTask(\n",
    "    text=True,\n",
    "    tables=True,\n",
    ")\n",
    "\n",
    "vdb_upload_task = VdbUploadTask()\n",
    "\n",
    "job_spec.add_task(extract_task)\n",
    "job_spec.add_task(embed_task)\n",
    "job_spec.add_task(vdb_upload_task)\n",
    "\n",
    "client = NvIngestClient(\n",
    "  message_client_hostname=\"localhost\",\n",
    "  message_client_port=7670\n",
    ")\n",
    "\n",
    "job_id = client.add_job(job_spec)\n",
    "\n",
    "client.submit_job(job_id, \"morpheus_task_queue\")\n",
    "\n",
    "result = client.fetch_job_result(job_id, timeout=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd083f-7e4d-4a96-ba36-c4c9c487f3c9",
   "metadata": {},
   "source": [
    "Next, we'll connect LlamaIndex to our collection in Milvus and create a new query engine from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88a9658c-6d5b-4cb0-ace2-2ef59cb8fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=\"http://localhost:19530\",\n",
    "    collection_name=\"nv_ingest_collection\",\n",
    "    doc_id_field=\"pk\",\n",
    "    embedding_field=\"vector\",\n",
    "    text_key=\"text\",\n",
    "    dim=1024,\n",
    "    overwrite=False\n",
    ")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store, embed_model=embed_model)\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef79dc-6976-450b-b04d-75f2a517569c",
   "metadata": {},
   "source": [
    "And then finally, we can query our Milvus vector database just as we did before with Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30cd73a-88e1-45cb-94e6-3d07deffe0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The dog is chasing a squirrel in the front yard.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query(\"What is the dog doing and where?\").response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2979c08-56a0-441f-87bf-2c6d0c8391a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
